0000|Selling FLOPs:
a New Export Industry for Developing Countries
0001|Michael Lokshin
0002|v20  —  February 16, 2026  00:15
0003|Abstract: The rapid growth of artificial intelligence is generating surging global demand for computational resources, yet the cost of producing a unit of computation varies by a factor of two across countries. This paper develops a trade model in which countries produce and export computing services (FLOPs), with costs determined by electricity prices, climate, and construction costs. The model distinguishes two services: AI training, which is latency-insensitive and can be offshored to the cheapest producer, and AI inference, which degrades with distance and favors proximity to users. A sovereignty premium captures governments’ preference for domestic data processing. Calibrating the model for 86 countries, the paper finds that many cheap-energy economies, including several low-income countries, could serve the world’s training needs, while regional inference hubs emerge around major demand centers. For developing countries with abundant energy but narrow export baskets, exporting compute opens a new entry point in the global economy, converting a natural resource directly into a high-value digital service.
0004|JEL Classification: F14, F18, L86, O14, O33, Q40
0005|Keywords: compute trade, FLOPs, artificial intelligence, data centers, comparative advantage, electricity costs, developing countries
0007|1. Introduction
0008|Demand for computational resources is driven by the expansion of artificial intelligence. The computation used to train the largest AI models has been doubling approximately every six months since 2010 (Epoch AI 2024), with inference workloads expected to account for roughly two-thirds of all compute by 2026 (Deloitte 2025). Data centers accounted for approximately 1.5% of global electricity demand in 2024, more than the entire electricity consumption of France, a share projected to double by 2030 (IEA 2025), with U.S. data center electricity consumption expected to triple over that period (EPRI 2024). AI-oriented facilities are qualitatively different from traditional cloud or enterprise data centers: they deploy thousands of GPUs at power densities of 40–100 kW per rack (versus 5–10 kW in conventional facilities), and can consume over 500,000 gallons of cooling water per day (Turner Lee and West 2025). This extreme power intensity makes electricity cost the dominant locational factor for AI compute.
0009|This surge in demand for computation creates a new type of export opportunity. In the Heckscher-Ohlin tradition, countries export goods intensive in their abundant factors. For FLOP exports, the relevant endowment is not cheap electricity per se but the natural resources that produce it: hydropower reservoirs (Kyrgyzstan, Ethiopia, Georgia), oil and gas (Iran, Turkmenistan, Qatar), solar irradiance (North Africa, the Gulf), and geothermal energy (Kenya, Iceland). The planned submarine cable linking Georgia and Azerbaijan to Romania, for example, is predicated on abundant Caucasus solar and gas resources. This paper refers to converting these resource endowments into exportable compute as FLOP exporting: the production of compute services in one country for consumption in another. FLOP exporting is a form of value chain upgrading—moving from low-value to higher-value activities within an industry. Rather than exporting raw energy resources as primary commodities, countries can convert cheap electricity into a higher value-added digital service. For energy-rich developing countries, FLOP exporting offers a route up the value chain without the heavy industrialization traditionally required for such upgrading (Hausmann, Hwang, and Rodrik 2007).
0010|Data center operations require minimal labor: a typical hyperscale facility employs only about 50 permanent staff (Uptime Institute 2024)—so the human capital constraints that have historically limited export upgrading in developing countries (Hausmann, Hwang, and Rodrik 2007) are largely absent.
0011|The opportunity is particularly relevant for the Europe and Central Asia (ECA) region. Several ECA countries, including Turkmenistan, Kyrgyzstan, and the countries of the South Caucasus, have among the world’s lowest electricity prices but limited integration into the global digital economy. Building data centers in these locations and selling compute services to high-cost markets could generate export revenue, attract foreign investment, and accelerate digital infrastructure development. Export-oriented capacity can also later serve the domestic market as local AI demand grows.
0012|Data center investments in developing countries confirm that FLOP exporting is already feasible. Armenia is deploying 50,000 GPUs in a $4 billion AI megaproject (Firebird 2026), while Kenya, Saudi Arabia, Morocco, Malaysia, and Indonesia have each attracted billion-dollar data center commitments. The economic stakes are substantial: a single 40 MW data center in Kyrgyzstan could generate annual revenue of $630 million–$950 million at wholesale contract rates, equivalent to over 15% of Kyrgyzstan’s $3.8 billion in goods exports (World Bank 2024).
0013|A growing literature examines compute governance and the geography of AI infrastructure (Sastry, Heim, et al. 2024, Lehdonvirta, Wu, and Hawkins 2024, Pilz, Mahmood, and Heim 2025), but no formal trade model of compute exists. This paper offers the first such model, treating FLOPs as commodities produced and exported according to Ricardian comparative advantage. The paper makes three contributions. First, it develops a trade model of FLOP production and export that decomposes the cost of a FLOP into electricity, hardware, and construction components, and introduces an iceberg trade cost for inference that captures latency degradation, alongside a sovereignty premium for domestic production preference. Second, it calibrates the model for 86 countries using data on electricity prices, climate, data center construction costs, and inter-country network latency, correcting for energy subsidies that distort headline cost rankings. Third, it characterizes the resulting trade regimes (which countries export, which import, and which adopt hybrid strategies) and shows how the sovereignty premium determines the boundary between domestic and foreign sourcing.
0014|The remainder of the paper is organized as follows. Section 2 reviews the related literature. Section 3 develops the model: production technology, trade costs, demand, and the capacity-constrained market equilibrium. Section 4 derives the equilibrium properties, including propositions on country taxonomy, concentration, sovereignty thresholds, and the nesting of training within inference exporters. Section 5 describes the data. Section 6 calibrates the model and discusses the results. Section 7 concludes.
0015|2. Related Literature
0016|Goldfarb and Trefler (2018) argue that AI shifts comparative advantage toward countries with data, human capital, and institutional capacity. The model introduces a complementary channel: comparative advantage in compute production depends on electricity costs and climate, so resource-rich countries could become compute exporters without domestic AI research industries. Korinek and Stiglitz (2021) raise the possibility that developing countries could be left behind in the AI revolution; FLOP exporting offers a route by which energy-rich developing countries could participate. The concept of FLOP exporting as value chain upgrading connects to Hausmann, Hwang, and Rodrik (2007), who show that what a country exports matters for growth. Limão and Venables (2001) demonstrate that infrastructure quality determines trade costs. In the model, network infrastructure plays the analogous role for digital trade. Krugman (1991) shows that increasing returns and transport costs interact to produce geographic concentration; analogous centripetal forces (network effects, colocation with internet exchanges, customer proximity) favor incumbent data center hubs. The model abstracts from these agglomeration economies to isolate cost-based comparative advantage, a simplification discussed further in the calibration.
0017|A growing literature examines the determinants of data center location. Flucker, Tozer, and Whitehead (2013) show that climate affects data center cooling costs. Oltmanns, Krcmarik, and Gatti (2021) model data center location as a function of electricity prices, climate, connectivity, and political stability. Liu et al. (2023) study data center placement under renewable energy constraints. These studies focus on where firms should build data centers. In international trade theory, Brainard (1997) formalizes the proximity-concentration trade-off between serving a market locally and concentrating production abroad, and Helpman, Melitz, and Yeaple (2004) extend this to heterogeneous firms choosing between exporting and FDI.
0018|Several recent papers address compute governance. Sastry, Heim, et al. (2024) argue that compute is well-suited for regulation because governments can track how many chips exist, restrict who buys them, and measure how much computation they perform. Lehdonvirta, Wu, and Hawkins (2024) map the global geography of cloud GPU infrastructure, distinguishing a “Compute North” with training-capable hardware from a “Compute South” limited to inference-grade chips. Pilz, Mahmood, and Heim (2025) project that AI data center power demand could reach 327 GW by 2030 and that domestic power shortages may push compute infrastructure abroad.
0019|3. Model Setup
0020|3.1 Production Technology and Cost Structure
0021|The existing literature documents where compute infrastructure is located and who controls it, but no formal framework links production costs to trade patterns. This section fills that gap by treating compute as a tradeable good whose production cost varies across countries, whose delivery cost differs between training (latency-insensitive) and inference (latency-sensitive), and whose sourcing is shaped by a sovereignty premium that captures governments’ preference for domestic production.
0022|The production of compute at scale takes place in data centers that house thousands of GPU-equipped servers. Consider  countries, each capable of producing compute services. The unit cost of producing one GPU-hour of compute in country  depends on three inputs: electricity, hardware, and data center construction.
0023|The key cost driver is the GPU’s power draw, the electrical power it consumes during operation. Power draw is denoted by , measured in kilowatts (kW). The actual electricity consumed depends also on the power usage effectiveness PUE(), where  is the peak summer temperature (°C) in country . PUE is the dimensionless ratio of total facility energy to IT equipment energy; it ranges from 1.08 in cold climates to over 1.4 in hot ones (Flucker, Tozer, and Whitehead 2013). PUE is modeled as:
0024|where  is the baseline PUE in cold climates,  is the PUE sensitivity per °C above the reference, and  is the reference temperature. These parameters are calibrated in Section 6.
0025|The total cost per GPU-hour in country  is:
0026|where  is the amortized hardware cost per GPU-hour: , with  the GPU purchase price,  the lifetime in years,  = 8,766 hours per year, and  the utilization rate. The term  captures networking costs (high-speed interconnect fabric such as InfiniBand), which can represent 15–25% of total system cost in a large training cluster (Barroso, Hölzle, and Ranganathan 2018). Both  and  are determined by global hardware markets and are common across countries. The first term is the PUE-adjusted electricity cost. The second is amortized hardware. The third is amortized construction. Cross-country variation in  is therefore driven by electricity prices, climate (through PUE), and construction costs.
0027|3.2 Trade Costs
0028|Following the trade-in-tasks framework of Grossman and Rossi-Hansberg (2008) and the iceberg cost structure of Eaton and Kortum (2002), countries produce and trade two types of compute services that differ in their offshoring costs. Training services encompass batch workloads: model training, fine-tuning, and large-scale data processing. Training a state-of-the-art AI model typically takes weeks to months on thousands of GPUs. The client ships its data to a data center; the computation executes locally, and the output is returned to the client. Since neither input nor output is time-sensitive, network latency plays no role. Inference services encompass real-time workloads: chatbot responses, autonomous decisions, and interactive agents. Each query must travel to the server and back within milliseconds, so the service degrades with delivery delay.
0029|Latency, denoted , is the round-trip time for a data packet to travel from server country  to demand center  and back, measured in milliseconds (ms). Within a country, latency is typically 5–10 ms; across continents, it can exceed 150 ms. For training, the workload ships to the producer, so effective latency is zero.
0030|Governments and firms may prefer to process data domestically for reasons of national security, regulatory compliance, or political preference. This is captured by a sovereignty premium , which acts as a proportional markup on the cost of foreign-sourced compute. When a country sources compute from a foreign producer, the effective cost is inflated by the factor . The sovereignty premium is zero for domestic production.
0031|The delivered cost of service  from producer  to demand center  is:
0032|where  if  (foreign sourcing) and  if  (domestic). The parameter  measures the rate of quality degradation per millisecond of round-trip latency, with  (training has zero effective latency) and  (inference degrades with latency). This iceberg formulation parallels Hummels and Schaur (2013), who estimate that each day of shipping time is equivalent to a tariff; here, milliseconds replace days and network latency replaces shipping time. In practice, GPU compute time (100–500 ms for a large language model response) dominates network round-trip time (20–150 ms). The latency penalty in equation (3) therefore captures only the incremental network component, making it a conservative estimate of the total latency cost of offshoring inference. This also implies that the geographic radius from which inference can be competitively served is wider than network latency alone would suggest.
0033|For training, equation (3) simplifies to : the delivered cost depends only on the production cost and whether the source is foreign. For inference, the full form of equation (3) applies, including the latency term. In practice, inference also faces a hard latency ceiling: beyond a threshold  (typically 200–300 ms for interactive applications), the service becomes unusable regardless of price. This is modeled as  if . Training workloads also incur data transfer costs: moving petabytes of training data to a remote facility requires substantial bandwidth and time. These data egress costs are not modeled explicitly but would further raise the effective cost of offshored training, particularly for bandwidth-constrained developing countries.
0034|3.3 Global Compute Demand
0035|The model is closed by specifying demand for compute services. Let  denote the volume of compute purchased by consuming country . Rather than relying on GDP as a proxy, the paper measures compute demand using installed data center capacity in megawatts (MW), compiled from industry sources:
0036|where  is total global compute spending and  is country ’s share of global demand, measured by its share of installed data center capacity (MW). Installed capacity is preferable to GDP as a demand proxy because compute consumption is driven by data center infrastructure, not aggregate income: Ireland and the Netherlands, for example, host far more capacity per capita than their GDP shares would predict, while large economies like India and Brazil account for modest shares of global data center power. Since all results below depend only on demand shares, not on the absolute level , the calibration does not require an estimate of total global compute spending.
0037|Demand splits between training and inference. Training demand is  and inference demand is , where  is the exogenous training share. The binary split between training and inference is a simplification. Emerging workload categories, notably agentic inference (long-running, multi-step reasoning tasks) and fine-tuning (rapid iterative retraining on proprietary data), occupy a middle ground: they tolerate moderate latency but require sustained GPU allocation and proximity to data. The model’s training share  should therefore be interpreted as the share of compute that is fully latency-insensitive and freely offshorable; the effective offshorable share may be smaller as agentic and fine-tuning workloads grow. Using installed capacity to proxy demand is a static assumption: it measures where compute demand currently sits, not where it will be as AI adoption grows. Endogenizing demand, for instance proportional to GDP or digital adoption, is a natural extension. The static specification is conservative in that it assigns demand to countries that already have infrastructure, understating export opportunities for low-cost producers that could serve future demand growth in emerging markets.
0038|3.4 Sourcing and Market Equilibrium
0039|For each service type , each consuming country  chooses the source that minimizes the delivered cost:
0040|Training market. Since , training is a homogeneous good with no distance-related quality degradation. Country  imports training whenever the world price, even after adding the sovereignty premium, is cheaper than producing domestically: , where  is the competitive world training price. Following Dornbusch, Fischer, and Samuelson (1977), countries are ranked by production cost: . In the capacity-constrained equilibrium, exporters fill demand in cost order: country (1) supplies up to its capacity, then country (2), and so on. The marginal training exporter  is the index at which cumulative capacity first meets export demand. The equilibrium training price equals the marginal exporter’s cost:
0041|Each country  is characterized by a capacity ceiling , measured in GPU-hours per period, representing the maximum volume of compute the country can supply. This ceiling reflects the joint constraint of grid electricity availability, institutional capacity for data center permitting and construction, and access to GPU financing. Without capacity constraints,  and the cheapest country serves all demand at its own cost, earning zero rent. With binding capacity constraints on cheap producers, , the price rises to the cost of the marginal entrant, and all infra-marginal exporters earn strictly positive Ricardian rents: . For a capacity-constrained exporter, the shadow value  of the grid constraint equals the margin on the least profitable active use, measuring the incremental gain from relaxing the capacity ceiling by one GPU-hour.
0042|Inference market. Since , inference suffers distance-dependent quality degradation. The inference market for demand center  is localized: only countries with latency  can participate, and each faces a different delivered cost. The FOB-equivalent inference price for demand center  is:
0043|where  is the marginal inference supplier to , determined by the capacity-constrained supply stack for ’s inference market. Each GPU-hour of capacity is allocated to its highest-margin use: training exports, inference exports to various destinations, or domestic supply. The aggregate rent function (derived in Appendix B) is concave and piecewise linear in total capacity deployed.
0044|4. Equilibrium Properties Results
0045|This section derives the formal properties of the capacity-constrained equilibrium defined in Section 3. Full derivations appear in Appendix B. All propositions hold for general parameter values; country-specific numerical examples are deferred to the calibration (Section 6).
0046|Proposition 1 (Country Taxonomy). In equilibrium, each country falls into exactly one of three regimes: (i) exporter (), when the country supplies compute to the world market up to its capacity; (ii) domestic producer (), when the sovereignty premium makes domestic production cheaper than importing; and (iii) importer (), when even with the sovereignty markup, foreign compute is cheaper. The three cases partition the cost space and are mutually exclusive.
0047|Proposition 2 (Capacity Constraints Reduce Concentration). Define the Herfindahl–Hirschman Index (HHI) for training market concentration as . Without capacity constraints, the cheapest producer captures all training demand and . With binding capacity constraints on the cheapest producers, , and  is strictly decreasing in the number of capacity-constrained infra-marginal exporters (U.S. DOJ and FTC 2010). The proof follows from the strict Cauchy-Schwarz inequality when at least two producers hold positive market shares.
0048|Proposition 3 (Sovereignty Switching Threshold). Country  produces training domestically if and only if . The threshold is increasing in  and decreasing in . Under capacity constraints, , so the threshold is lower than in the unconstrained model: capacity constraints lower the sovereignty premium needed for domestic production because the higher world price makes imports more expensive.
0049|Proposition 4 (Shadow Value and Grid Expansion). For a capacity-constrained exporter, the shadow value  of the grid constraint equals the margin on the least profitable active use (Section 3.4). Grid expansion is warranted if and only if the amortized per-GPU-hour cost of grid infrastructure  satisfies . This follows directly from the concavity of the rent function.
0050|Proposition 5 (Training Exporters Nest Within Inference Exporters). The set of training exporters is a subset of inference exporters for demand centers within the latency threshold . A training exporter has the globally lowest ; for inference to proximate demand centers, this cost advantage dominates the latency markup, so the same country wins the inference competition. Since training has no distance penalty while inference does, every country that exports training is also competitive in inference for its geographic neighborhood, but not vice versa.
0051|Welfare cost of sovereignty. The sovereignty premium imposes a welfare cost with two components: an import markup (importers pay  per unit above the competitive price) and an allocative inefficiency (countries with  produce domestically at above-world-price costs). Under capacity constraints, both components are smaller than in the unconstrained model because the higher world price narrows the gap between domestic and import costs.
0052|Demand spillover. When a low-cost exporter hits its capacity ceiling, excess demand spills to the next cheapest feasible supplier. This cascade mechanism generates a distinctive pattern: countries that would be excluded from the export market in the unconstrained model become second-tier exporters when cheaper countries are capacity-constrained, providing a theoretical foundation for mid-cost countries capturing meaningful export shares.
0053|5. Data
0054|Calibrating the production-cost and trade-cost parameters in equations (2) and (3) requires data on electricity prices, temperatures, construction costs, and bilateral latencies. Electricity prices. For European countries, the paper uses Eurostat industrial electricity prices in the 20,000–69,999 MWh consumption band, which corresponds to large industrial consumers (Eurostat 2025). For non-European countries, the paper uses national regulator tariff sheets and secondary sources: U.S. Energy Information Administration (EIA 2025) for the United States; KEPCO for South Korea; national utility tariffs for Central Asian countries (Barki Tojik, AERA, Ministry of Energy of Uzbekistan); and GlobalPetrolPrices (2025) for remaining countries. All prices are converted to USD/kWh at 2024 average exchange rates.
0055|Temperature and construction. Peak summer temperature for each country is computed from ERA5 reanalysis data (Hersbach et al. 2020) as the average monthly maximum in the three warmest months, aggregated across populated grid cells. Data center construction costs per watt of IT capacity are from the Turner & Townsend Data Centre Construction Cost Index 2025, which reports actual costs ($/W) for 37 countries across 52 markets (Turner & Townsend 2025). For the remaining countries, construction costs are predicted using a log-linear regression of ln($/W) on ln(GDP per capita), urban population share, a seismic zone indicator, and World Bank regional dummies (). The moderate explanatory power reflects the fact that construction costs depend on factors such as labor markets, building codes, and imported-materials logistics that these variables capture imperfectly. Since construction is only 3–6% of total FLOP costs, imputation error matters less than it might seem: 95% prediction intervals for imputed countries span about ±$3.50/W, which translates to ±$0.02/hr in total cost (1.5–2% of the mean). Costs are amortized over 15 years. The per-GPU construction cost in equation (2) equals 700 W (the GPU thermal design power) times the build cost per watt.
0056|Latency. Inter-country round-trip latency is measured using WonderNetwork’s global ping dataset (WonderNetwork 2024). For each country pair, the median round-trip time (RTT) in milliseconds is used. Domestic latency defaults to 5 ms where no intra-country measurement is available. These measurements reflect today’s network infrastructure. New undersea cables, terrestrial fiber, and CDN expansions could cut bilateral latencies enough to redraw inference trade patterns, opening distant low-cost producers to markets they cannot currently reach. Hardware. The calibration uses the NVIDIA H100 SXM GPU as the reference hardware platform: list price $25,000, thermal design power 700W, economic lifetime 3 years, utilization rate 90% (NVIDIA 2024). This yields an amortized hardware cost /hr. The 90% utilization rate is aspirational: Google’s fleet-wide GPU utilization, after years of optimization with custom schedulers and workload packing, runs in the 60–75% range (Barroso, Hölzle, and Ranganathan 2018). At 70% utilization, hardware cost rises to $1.36/hr, compressing the cost advantages in Table A2. A new entrant in Central Asia would likely achieve 40–60% utilization in early years, which would roughly double the effective hardware cost per useful GPU-hour. Networking costs are calibrated at /hr, based on the amortized cost of InfiniBand interconnect fabric per GPU over the same three-year horizon (Barroso, Hölzle, and Ranganathan 2018). Like hardware, networking equipment is procured at uniform global prices, so this term does not affect cross-country cost rankings. GPU prices are assumed uniform across countries. In practice, export controls, logistics costs, insurance, and local distribution markups can raise effective GPU prices by 5–15% in developing countries. A 10% GPU price premium would add roughly $0.10/hr to unit costs, substantially eroding the thin cost advantages documented in Table A2. This assumption thus works in favor of developing-country exporters and should be kept in mind when interpreting the calibration results.
0057|Other parameters. The latency degradation parameter is set at , implying that 100 ms of latency inflates inference cost by 8%. This value is calibrated to match the observed willingness of cloud providers to invest in regional points of presence: at , a latency difference of 100 ms (roughly the intercontinental round-trip between Europe and East Asia) imposes an 8% cost penalty, consistent with industry evidence that web-service revenue declines by approximately 1% per 100 ms of additional latency. The sovereignty premium is . The training share of compute demand is , within the industry range of 0.4–0.6 (Deloitte 2025). Sensitivity to all three parameters is explored in Section 6.
0058|Demand. Compute demand  is proxied by installed data center capacity in MW, as specified in equation (4). For the top 15 markets, capacity estimates come from industry reports (Synergy Research, Cushman & Wakefield, CBRE, Mordor Intelligence); for smaller markets, capacity is estimated from facility counts and regional averages. The five largest demand centers (United States of America (43%), China (26%), India (2.9%), Canada (3%), and Australia (2%)) account for 77% of global demand. MW capacity captures the scale of compute infrastructure more accurately than facility counts: Chinese data centers, though fewer in number (449 in Cloudscene), are substantially larger on average, and IEA (2025) data confirm that China accounts for roughly 25% of global data center electricity consumption versus 44% for the United States. Table A1 in the Appendix reports the capacity estimates for all countries.
0059|6. Calibration and Discussion
0060|The model is calibrated for  countries (30 in ECA, 55 non-ECA comparators), in the spirit of the multi-country Ricardian tests of Costinot, Donaldson, and Komunjer (2012). The unit cost  represents the total hourly cost of operating one GPU in country , measured in dollars per GPU-hour ($/hr). The PUE parameters in equation (1) are calibrated as follows. The baseline  matches Google’s reported fleet-wide PUE for facilities with free-air cooling in cold climates (Uptime Institute 2024). The sensitivity coefficient  per °C is estimated from cross-sectional variation in PUE across data center locations with different cooling loads (Liu et al. 2023). The threshold  is the approximate outdoor temperature above which mechanical cooling is needed, below which free-air cooling suffices. Together, these yield PUE values from 1.08 (Iceland, Scandinavia) to 1.41 (UAE), consistent with the industry range of 1.1–1.6 reported by the Uptime Institute.
0061|Table A2 in the Appendix reports the full results for all  countries, sorted by unit cost under observed electricity prices. Under observed tariffs, the cheapest producer is Iran ($1.41/hr), followed by Turkmenistan ($1.11/hr) and Kyrgyzstan ($1.13/hr). But this ranking is misleading. Iran’s headline cost rests on electricity priced at $0.005/kWh, a figure sustained by one of the world’s largest fossil fuel subsidies. Turkmenistan, Algeria, Qatar, and several other low-cost producers face similar distortions. Construction costs account for 3–6% of total costs, ranging from $0.033/hr (China) to $0.078/hr (Japan, Singapore). The Nordics benefit from low PUE (1.08–1.10). At the expensive end, Ireland ($1.28/hr) and Greenland ($1.32/hr) face high electricity prices.
0062|To distinguish genuine comparative advantage from fiscal artifact, the calibration replaces subsidized tariffs with cost-recovery prices: the long-run marginal cost (LRMC) of the dominant generation technology at opportunity-cost fuel prices (IMF 2025, Lazard 2025). This adjustment is applied to 13 countries whose retail electricity prices fall below estimated LRMC. Hydropower producers (Kyrgyzstan, Canada, Norway) are not adjusted because their low prices reflect genuine resource advantages, not fiscal transfers. The resulting cost-recovery ranking is the paper’s preferred baseline. The five cheapest producers become Kyrgyzstan ($1.58/hr), Canada ($1.59/hr), Ethiopia ($1.59/hr), Kosovo ($1.60/hr), and Tajikistan ($1.60/hr). A sovereignty premium  shifts the majority of countries to domestic production. The sovereignty premium is particularly powerful for inference: since the latency markup within Europe is moderate (10–40 ms, adding 1–3%), even a small domestic preference tips the decision away from importing.
0063|In practice,  is bilateral and heterogeneous. Between allies with mutual data adequacy agreements (e.g., EU member states), the effective sovereignty premium may be near zero. Between geopolitical adversaries, it is effectively infinite: the United States would not source training from Iran regardless of cost, and current sanctions make such transactions illegal. The uniform  should therefore be understood as an average over non-adversarial country pairs. In a model with bilateral , sanctioned countries would be excluded from serving most demand centers. Under cost-recovery prices, Iran is already outside the top ten, so sanctions reinforce rather than alter the cost-recovery ranking.
0064|The country-specific switching threshold  from Section 4 varies widely across the calibration. Near-frontier countries, whose production costs are close to the cheapest global supplier, switch to domestic production with minimal sovereignty premia: Kyrgyzstan requires only , China 0.8%, and the United States 2.6%. High-cost countries require much larger premia: Germany needs  and Japan 6.9%. Countries with high  face large cost penalties from sovereignty-driven domestic sourcing.
0065|Trade flows under capacity constraints. Weighting the sourcing patterns by demand shares from equation (4) and applying capacity constraints from Section 3.4, the equilibrium training price is /hr, set by the marginal exporter’s cost. Training demand is served by 2 exporters (HHI = 0.93), confirming Proposition 2. The largest shadow values of grid capacity are: Kyrgyzstan ($0.014/hr), consistent with Proposition 4. Inference is more dispersed: the top five suppliers are Canada (46%), Kyrgyzstan (26%), Kosovo (6%), United Kingdom (3%), India (3%), together serving 84% of global inference demand (HHI = 0.29). Under the 10% sovereignty premium, most training demand is served domestically, and the smaller export market is served by 1 exporter (HHI = 1.00) at $1.58/hr.
0066|Among developing countries, Kyrgyzstan captures 26% of global inference demand by serving China, Kazakhstan, and Uzbekistan, a striking result for a country with GDP under $15 billion. Kosovo serves as an inference hub for 17 countries, accounting for 6% of global inference demand. These patterns show how cheap-energy developing countries can earn export revenue from much larger economies.
0067|Doubling the sovereignty premium to 20% shifts 1 additional country to domestic training production, reducing the share of global training demand available to foreign producers from 0% to 0%. At 20%, nearly all countries produce training domestically, and the export market for training effectively disappears. Inference export revenue is more resilient to sovereignty premia because the latency advantage of proximity partially insulates regional hubs.
0068|Major demand centers. The model’s predictions vary across major AI demand centers because each faces a different latency geography. For the United States, the cost-recovery optimum sources training from the cheapest available producer and inference from Canada ($1.66/hr). For Germany, inference is sourced from Kosovo ($1.65/hr); for the United Kingdom from United Kingdom ($1.66/hr); and for France from Kosovo ($1.66/hr). For China, the cheapest inference source is Kyrgyzstan ($1.63/hr), a bordering country with hydropower-based electricity. These patterns illustrate the model’s core prediction: inference organizes around latency-bounded regional hubs, and each major market has a distinct optimal supplier determined by geography. With a sovereignty premium of 10%, most large economies shift to full domestic production.
0069|Governance and political economy. These cost rankings assume globally uniform hardware prices and abstract from institutional heterogeneity. In practice, GPU export controls raise effective  for Iran, Russia, and Belarus; and grid reliability varies widely. Data center investments are large, long-lived, and immobile, so the viability of a country as a compute exporter depends on institutional factors not captured by  alone. Several of the cheapest producers in the calibration (Iran, Turkmenistan, Uzbekistan) rank poorly on property rights and rule of law indices, and subsidized electricity prices may be politically fragile. Effective entry barriers are therefore higher than production costs alone suggest.
0070|The EU’s GDPR and AI Act segment the compute market along regulatory lines, reinforcing the sovereignty premium  as a structural feature. U.S. export controls on advanced GPUs (October 2022 and October 2023 rules, expanded in 2025) create a hard binary constraint for certain jurisdictions: H100-class GPUs cannot legally be shipped there at all, making the relevant question availability rather than price. For countries not under outright bans but subject to per-chip caps, the effective hardware cost  rises through grey-market procurement, potentially offsetting any electricity cost advantage and discouraging long-term investment. Grid reliability further narrows the set of viable exporters: countries with frequent outages face backup-generation costs that are not reflected in headline electricity prices; therefore, effective costs should be understood as reliability-adjusted. Taken together, these governance factors suggest that viable compute exporters are a strict subset of low-cost producers: those that combine cheap energy with adequate institutional quality, such as the Nordic countries, Canada, and parts of the Gulf and Central Asia. Water is another constraint. Evaporative cooling consumes large volumes, and several of the cheapest producers (Iran, Turkmenistan, Egypt, Saudi Arabia) are water-scarce. Liquid cooling reduces water needs but does not eliminate them.
0071|The sovereignty premium deserves scrutiny. Some domestic processing preference is justified for genuinely confidential data (military intelligence, health records, national statistical systems). But much of the current policy push, particularly in the EU, extends the sovereignty logic far beyond these cases to cover routine commercial computation that carries no security risk. The welfare cost is not trivial: as shown above, a 10% premium already shifts the majority of countries to domestic production, forgoing the cost savings from specialization. Developing countries in Central Asia and Africa are likely to follow the EU template, imposing data localization requirements that their small markets cannot efficiently serve. The irony is that the same countries whose cost advantages make them natural FLOP exporters may simultaneously erect sovereignty barriers against importing compute from their neighbors, undermining the regional trade the model predicts would be welfare-improving.
0072|Subsidy adjustment. The cost-recovery prices are derived from country-specific LRMC estimates. For gas exporters (Iran, Turkmenistan, Algeria, Qatar), the calibration uses combined-cycle gas generation at export-parity fuel prices ($0.065–$0.100/kWh). For the Gulf states, it uses the opportunity cost of domestic gas combustion versus LNG export. For coal-dependent producers (Kazakhstan, South Africa), the calibration uses the Eskom-style cost-recovery tariff. For Ethiopia, it uses the IMF’s hydro cost-recovery target ($0.050/kWh). The subsidy gap ranges from $0.019 to $0.080/kWh; for Iran, a 100 MW data center would receive roughly $70 million per year in implicit fiscal transfer. At export scale, this fiscal arithmetic becomes unsustainable. Even cost-recovery prices may understate the true resource cost: regulated tariffs in many developing countries cover operating expenses but not the full capital cost of generation, transmission, and distribution infrastructure. Energy state-owned enterprises (SOEs) accumulate quasi-fiscal deficits that are eventually borne by taxpayers or future consumers. Allowing large-scale FLOP exports at these prices would accelerate infrastructure depreciation while the SOE cannot finance replacement, raising a fundamental question: is it politically sustainable to export compute while the domestic energy sector cannot maintain its capital stock? Governments ultimately face a choice between raising data center tariffs (eroding the cost advantage), maintaining subsidies at growing fiscal cost, or capping capacity. Iran drops from first to 24th; eight countries change trade regime.
0073|Endogenous electricity prices. The model treats electricity prices as exogenous parameters. For large economies this is innocuous, but for the small, cheap-energy countries that rank highest in Table A2, a hyperscale data center can be large relative to the host grid. Kyrgyzstan’s installed generation capacity is approximately 3,500 MW; a single 100 MW facility would consume roughly 5% of national electricity output, and at the multi-facility scale implied by the model’s export predictions, data centers would become the dominant industrial load. At that scale, the assumption of price-taking behaviour breaks down: increased demand would bid up wholesale electricity prices, competing with residential heating in winter (when Kyrgyz hydropower output drops), and likely triggering regulatory intervention. The cheap electricity that attracts investment would be partially eroded by the investment itself. The capacity ceiling  partially addresses this concern by capping each country’s compute output, but within the feasible range, the model’s fixed-price assumption means that the cost advantages in Table A2 are upper bounds. A general equilibrium extension with upward-sloping electricity supply curves would compress these advantages further and narrow the set of viable exporters.
0074|Sensitivity analysis. The cost rankings in Table A2 are robust to substantial parameter variation. Across six scenarios—electricity prices ±$0.01/kWh, GPU price ±20%, utilization at 70%, and PUE capped at 1.20—the Spearman rank correlation with the baseline never falls below 0.992. The top five cheapest countries are unchanged in five of six scenarios. The training price shifts by at most $0.302/hr. The reason is straightforward—hardware amortization accounts for approximately 94 percent of total cost and is identical for all countries. Only the electricity and construction components vary cross-country, and their combined share is too small for plausible perturbations to overturn the ordering.
0075|Model extensions. The model can be extended in several directions. It can accommodate endogenous capacity investment, allowing countries to optimally choose their capacity ceiling rather than taking grid limits as given. It can incorporate stochastic disruptions such as grid outages or political instability, giving buyers a reason to diversify workloads across providers. Demand can be segmented by latency tolerance to capture heterogeneous service requirements. Carbon pricing can introduce a “green premium” that favors hydropower-rich countries. The framework can also accommodate strategic interaction among oligopolistic providers, and governance can enter as a multiplicative cost shifter on .
0076|Agglomeration and market structure. The competitive framework abstracts from the industrial organization of the cloud compute market, which is dominated by a small number of hyperscalers (AWS, Azure, Google Cloud) with significant scale economies, proprietary networks, and market power. In practice, whether a country becomes a compute exporter depends not only on unit costs but on whether a hyperscaler or colocation provider chooses to invest there, a decision shaped by agglomeration economies, institutional quality, and network connectivity (Krugman 1991). The concentration of data centers in locations such as Northern Virginia reflects precisely these centripetal forces.
0077|The model’s contribution is to identify which countries satisfy the necessary cost condition for competitive supply. Even under increasing returns, hyperscalers expanding internationally will favor locations where electricity, cooling, and construction costs are lowest, conditional on meeting minimum infrastructure thresholds. The cost ranking in Table A2 thus identifies the feasibility frontier: countries that are cost-competitive have a prerequisite for attracting investment, though cost competitiveness alone is not sufficient. The thin margins documented above (a 20% spread between cheapest and most expensive) reinforce this point: since unit cost advantages are modest, institutional and agglomeration factors will often be decisive in determining which cost-competitive countries actually attract investment.
0078|7. Conclusion
0079|This paper develops a capacity-constrained Ricardian model for trade in computing services (FLOPs) in which countries produce and export computing capacity based on their electricity prices, climate, and construction costs. The model distinguishes two service types, latency-insensitive training and latency-sensitive inference, and introduces a sovereignty premium to capture governments’ preference for domestic data processing. Capacity ceilings transform the classical Ricardian assignment into a framework with market-clearing prices and Ricardian rents. The paper calibrates the model for 86 countries using data on electricity prices, temperatures, construction costs, bilateral latencies, and grid capacity.
0080|Across 86 countries, cheap-energy peripheries serve as FLOP exporters for training, while inference organizes into regional hubs bounded by latency. The sovereignty premium rationalizes widespread domestic investment, shifting the majority of countries from import to domestic production, at a demand-weighted welfare cost of 6.0% of average compute spending, comparable in magnitude to the 1–10% welfare losses from trade barriers estimated for goods trade (Arkolakis, Costinot, and Rodríguez-Clare 2012). The model generates a country taxonomy (full importers, training exporters, inference hubs, and hybrid regimes) that maps onto observed investment patterns. This geographic structure is consistent with Lehdonvirta, Wu, and Hawkins (2024), who independently find that training-capable GPU infrastructure is concentrated in roughly 30 countries while the rest are limited to inference-grade hardware.
0081|For developing countries, the results point to a new avenue for economic participation in the global economy. Countries like Kyrgyzstan, Uzbekistan, and Egypt, which rank among the cheapest FLOP producers in the calibration, could convert cheap electricity into a high-value digital export without building a domestic AI research ecosystem. FLOP exporting is the digital equivalent of resource-based industrialization, but with the advantage that the “resource” (electricity) need not deplete a finite reserve and the product (compute) serves the fastest-growing sector of the world economy. That said, the resource curse literature (van der Ploeg 2011) cautions that concentrated export revenues can produce Dutch disease, institutional degradation, and volatility. Whether FLOP exporting shares these risks depends on whether the revenues are broad-based or captured by a narrow set of actors, and on whether governments invest the proceeds in human capital and institutional development.
0082|The policy implications are asymmetric. Restricting training imports raises costs without a proximity benefit, since training is latency-insensitive. Supporting domestic inference has a genuine latency rationale, but is less justified for countries close to low-cost neighbors. For developing countries seeking to enter the compute export market, the binding constraints are not technological but institutional. Reliable power grids, political stability, data governance frameworks, and international connectivity determine whether cost advantages translate into actual exports.
0084|References
0085|Arkolakis, C., A. Costinot, and A. Rodríguez-Clare. (2012). “New Trade Models, Same Old Gains?” American Economic Review, 102(1): 94–130.
0086|Barroso, L., U. Hölzle, and P. Ranganathan. (2018). The Datacenter as a Computer: Designing Warehouse-Scale Machines, 3rd ed. San Rafael, CA: Morgan & Claypool.
0087|Brainard, S. (1997). “An Empirical Assessment of the Proximity-Concentration Trade-off.” American Economic Review, 87(4): 520–544.
0088|Cloudscene. (2025). Global Data Center Directory. cloudscene.com.
0089|Costinot, A., J. Donaldson, and I. Komunjer. (2012). “What Goods Do Countries Trade? A Quantitative Exploration of Ricardo’s Ideas.” Review of Economic Studies, 79(2): 581–608.
0090|Deloitte and Google. (2020). “Milliseconds Make Millions.” Deloitte Digital and Google.
0091|Deloitte. (2025). “Technology, Media, and Telecommunications Predictions 2026.” Deloitte Insights.
0092|Dornbusch, R., S. Fischer, and P. Samuelson. (1977). “Comparative Advantage, Trade, and Payments in a Ricardian Model with a Continuum of Goods.” American Economic Review, 67(5): 823–839.
0093|Eaton, J., and S. Kortum. (2002). “Technology, Geography, and Trade.” Econometrica, 70(5): 1741–1779.
0094|EIA. (2025). Electric Power Monthly. U.S. Energy Information Administration.
0095|Epoch AI. (2024). “The Training Compute of Notable AI Models.” epochai.org.
0096|EPRI. (2024). “Powering Intelligence: Analyzing AI and Data Center Energy Consumption.” Electric Power Research Institute.
0097|Eurostat. (2025). Electricity Prices for Non-Household Consumers (nrg_pc_205). Luxembourg: Eurostat.
0098|Firebird. (2026). “Phase 2 of Armenia AI Megaproject, Scaling to $4 Billion and 50,000 GPUs.” Press release, January 2026.
0099|Flucker, S., R. Tozer, and R. Whitehead. (2013). “Data Centre Energy Efficiency Analysis.” Building Services Engineering Research and Technology, 34(1): 103–117.
0100|GlobalPetrolPrices. (2025). Electricity Prices Around the World. globalpetrolprices.com.
0101|Goldfarb, A., and D. Trefler. (2018). “AI and International Trade.” In The Economics of Artificial Intelligence. Chicago: Univ. of Chicago Press, pp. 463–492.
0102|Grossman, G., and E. Rossi-Hansberg. (2008). “Trading Tasks: A Simple Theory of Offshoring.” American Economic Review, 98(5): 1978–1997.
0103|Hausmann, R., J. Hwang, and D. Rodrik. (2007). “What You Export Matters.” Journal of Economic Growth, 12(1): 1–25.
0104|Helpman, E., M. Melitz, and S. Yeaple. (2004). “Export Versus FDI with Heterogeneous Firms.” American Economic Review, 94(1): 300–316.
0105|Hersbach, H., et al. (2020). “The ERA5 Global Reanalysis.” Quarterly Journal of the Royal Meteorological Society, 146(730): 1999–2049.
0106|Hummels, D., and G. Schaur. (2013). “Time as a Trade Barrier.” American Economic Review, 103(7): 2935–2959.
0107|IEA. (2025). “Energy Demand from AI.” Published online at iea.org.
0108|IMF. (2025). “Fossil Fuel Subsidies Data: 2025 Update.” IMF Working Paper WP/25/270.
0109|Korinek, A., and J. Stiglitz. (2021). “AI, Globalization, and Strategies for Economic Development.” NBER Working Paper No. 28453.
0110|Krugman, P. (1991). “Increasing Returns and Economic Geography.” Journal of Political Economy, 99(3): 483–499.
0111|Lazard. (2025). Lazard’s Levelized Cost of Energy Analysis, Version 17.0. lazard.com.
0112|Lehdonvirta, V., B. Wu, and Z. Hawkins. (2024). “Compute North vs. Compute South: The Uneven Possibilities of Compute-Based AI Governance Around the Globe.” Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society, 7(1): 828–838.
0113|Limão, N., and A. Venables. (2001). “Infrastructure, Geographical Disadvantage, Transport Costs, and Trade.” World Bank Economic Review, 15(3): 451–479.
0114|Liu, Z., A. Wierman, Y. Chen, B. Raber, and J. Moriarty. (2023). “Sustainability of Data Center Digital Twins.” Proceedings of ACM e-Energy, pp. 178–189.
0115|NVIDIA. (2024). NVIDIA H100 Tensor Core GPU Datasheet. nvidia.com.
0116|Oltmanns, J., D. Krcmarik, and R. Gatti. (2021). “Data Centre Site Selection.” Journal of Property Investment & Finance, 39(1): 55–72.
0117|Pilz, K., Y. Mahmood, and L. Heim. (2025). AI’s Power Requirements Under Exponential Growth. Santa Monica, CA: RAND Corporation, RR-A3572-1.
0118|Sastry, G., L. Heim, et al. (2024). “Computing Power and the Governance of Artificial Intelligence.” arXiv:2402.08797.
0119|Turner & Townsend. (2025). Data Centre Construction Cost Index 2025. turnerandtownsend.com.
0120|Turner Lee, N., and D. West. (2025). “The Future of Data Centers.” Brookings Institution, November 2025.
0121|U.S. Department of Justice and Federal Trade Commission. (2010). Horizontal Merger Guidelines. Washington, DC.
0122|UNCTAD. (2025). Technology and Innovation Report 2025. Geneva: United Nations.
0123|Uptime Institute. (2024). “Data Center Staffing: Trends and Best Practices.” uptimeinstitute.com.
0124|van der Ploeg, F. (2011). “Natural Resources: Curse or Blessing?” Journal of Economic Literature, 49(2): 366–420.
0125|WonderNetwork. (2024). Global Ping Statistics. wondernetwork.com.
0126|World Bank. (2024). World Development Indicators. Washington, DC.
0128|Appendix
0129|Table A1. Calibration parameters and data center capacity
0130|Panel A: Model parameters
0131|Notes: γ = GPU thermal design power (NVIDIA H100). Pɢᴘᴜ = GPU purchase price. L = GPU useful life. β = GPU utilization rate (fraction of time actively computing). H = hours per year. ρ = amortized hardware cost per GPU-hour = Pɢᴘᴜ / (L · H · β). η = amortized networking cost per GPU-hour (InfiniBand interconnect). φ = PUE baseline (best-practice free-air cooling). δ = PUE temperature sensitivity coefficient per °C. θ̄ = free-cooling temperature threshold. D = data center facility lifetime. τ = latency degradation factor per millisecond of round-trip time. λ = sovereignty premium (fraction above market price for domestic compute). α = training share of total compute demand. Q = total global compute demand. Sources: NVIDIA (2024), Turner & Townsend (2025), Uptime Institute (2024), Epoch AI (2024), Liu et al. (2023).
0132|Panel B: Data center capacity and demand shares
0133|Notes: Rank = rank by installed data center capacity (descending). Capacity (MW) = installed data center power capacity in megawatts (Mₖ in the model). Demand Share (ωₖ in the model) = country share of global compute demand from equation (4): ωₖ = Mₖ / Σ M. Source = primary data source for the capacity estimate (Synergy = Synergy Research 2024; C&W = Cushman & Wakefield; CBRE = CBRE Research; Mordor = Mordor Intelligence; Estimated = DC count × regional average).
0135|Table A2. Unit cost of FLOP production by country (H100 GPU-hour)
0136|Notes: Rank = cost rank under observed electricity prices. Adj. Rank = rank after replacing subsidized electricity prices with cost-recovery estimates (— if unchanged). Total Cost (cⱼ in the model) = hourly cost of operating one H100 GPU, equal to electricity + amortized hardware at $1.36/hr + amortized construction. Electricity Cost = hourly electricity component (PUE × GPU power draw × price). Construction Cost = amortized hourly data center construction cost. PUE = Power Usage Effectiveness from equation (1); PUE(θⱼ) = φ + δ · max(0, θⱼ − θ̄). Elec. Price (pᴱ in the model) = national electricity price for industrial/data center consumers. Cost-Recov. Price = estimated long-run marginal cost of electricity generation for the 13 countries with subsidized electricity; — for unsubsidized countries. Pure-Cost Regime = optimal sourcing strategy from equation (5) without sovereignty premium: domestic (produce both services), hybrid (import training, produce inference), or import (import both).
0138|Appendix B: Model Derivation
0139|This appendix provides the full derivation of the capacity-constrained Ricardian model summarized in Sections 3–4.
0140|B.1 Primitives
0141|Each country  is endowed with a capacity ceiling  (GPU-hours per period), representing the maximum volume of compute it can supply. Country  faces unit production cost  from equation (2). On the demand side, total compute demand from country  is  from equation (4). Training demand is  and inference demand is . Countries are ordered by cost: .
0142|B.2 The Training Market
0143|Country  imports training if and only if . The set of training importers is  and total training export demand is . The marginal training exporter  is defined by:
0144|The equilibrium training price is . Training rent for country  with  is .
0145|B.3 The Inference Market
0146|The feasible supplier set for demand center  is . The marginal cost of delivering one effective unit of inference from  to  is:
0147|The inference rent per GPU-hour allocated to serving  is .
0148|B.4 Capacity Allocation
0149|Each GPU-hour is allocated to its highest-margin use. The margins per GPU-hour are: training exports ; inference exports to : . Total rent from operating  GPU-hours is:
0150|which is concave and piecewise linear in .
0151|B.5 Equilibrium Definition and Existence
0152|A competitive equilibrium consists of a training price , inference prices , and capacity allocations  such that: (i) each GPU-hour is allocated to its highest-margin use; (ii) training and inference markets clear; (iii) all allocations are feasible (). Existence follows from a fixed-point argument: the training supply curve is a step function with steps at  and widths ; intersection with the demand curve pins down .
0153|B.6 Welfare Cost of Sovereignty
0154|The welfare cost has two components. Import markup:
0155|Allocative inefficiency:
0156|Total: . Under capacity constraints, both components are smaller because the higher  narrows the gap between domestic and import costs.
