[0|Normal|B] Comparative Advantage in Compute Exports:
A Two-Segment Model with Heterogeneous Trade Costs
[1|Heading 2|I] Abstract
[2|Normal|] The rapid growth of artificial intelligence is generating unprecedented global demand for computational resources, yet the cost of producing a unit of computation varies by a factor of two across countries. We develop a trade model in which countries produce and export computing services (FLOPs), with costs determined by electricity prices, climate, and construction costs. The model distinguishes two services: AI training, which is latency-insensitive and can be offshored to the cheapest producer, and inference, which degrades with distance and favors proximity to users. A sovereignty premium captures governments’ preference for domestic data processing. Calibrating the model for 82 countries, we find that a handful of cheap-energy economies — many of them developing countries — could serve the world’s training needs, while regional inference hubs emerge around major demand centers. For developing countries with abundant energy but limited industrial bases, exporting compute opens a new pathway into the global economy: one that bypasses traditional manufacturing and converts a natural resource directly into a high-value digital service.
[3|Normal|] 
[4|Normal|B] JEL Classification: F14, F18, L86, O14, O33, Q40
[5|Normal|B] Keywords: compute trade, FLOPs, artificial intelligence, data centers, comparative advantage, electricity costs, developing countries
[6|Heading 1|] 1. Introduction
[7|Normal|] The rapid expansion of artificial intelligence is creating unprecedented demand for computational resources. The amount of computation used to train frontier AI models has been doubling approximately every six months, growing at a rate of 4.4× per year (Epoch AI, 2024). The global GPU server market, valued at $171 billion in 2025, is projected to reach $731 billion by 2030 (MarketsandMarkets, 2025). AI data center capital expenditure is expected to reach $400–450 billion in 2026 alone, rising to $1 trillion by 2028 (Deloitte, 2025). Moreover, inference workloads — the real-time generation of predictions and responses — are expected to account for roughly two-thirds of all compute by 2026 (Deloitte, 2025). This structural shift has direct implications for the geography of compute production, since inference, unlike training, is sensitive to the physical distance between server and user.
[8|Normal|] The electricity footprint of this demand is enormous. Data centers consumed approximately 415 TWh of electricity in 2024 — roughly 1.5% of global electricity demand — and this figure is projected to reach 945 TWh by 2030 (IEA, 2025). Goldman Sachs (2024) estimates a 165% increase in data center power demand over the same period. In the United States, data center electricity consumption is expected to triple by 2030 (EPRI, 2024). Major technology firms are signing multi-gigawatt power purchase agreements, reopening retired nuclear plants, and investing in new generation capacity to secure electricity for AI workloads.
[9|Normal|I] This surge in demand creates a new type of export opportunity. Countries with abundant, inexpensive electricity and land — many of them developing economies — could produce and export computational services, measured in floating-point operations per second (FLOP/s). We call this FLOP exporting: the production of compute services in one country for consumption in another. Crucially, FLOP exporting represents a form of value chain upgrading. Rather than exporting raw energy resources — oil, natural gas, or coal — as primary commodities, countries can convert cheap electricity into a higher value-added digital service. Just as exporting refined petroleum products captures more value than exporting crude oil, exporting FLOPs captures more value than exporting the kilowatt-hours that power them. For energy-rich developing countries, FLOP exporting offers a pathway to move up the value chain without the heavy industrialization traditionally required for such upgrading (Hausmann, Hwang, and Rodrik, 2007).
[10|Normal|] Unlike traditional manufacturing, data center operations require minimal labor. A typical hyperscale facility of 40 MW houses over 6,000 servers with approximately 53,000 GPUs, yet employs only about 50 permanent staff (Uptime Institute, 2024). The binding input is cheap electricity, not abundant skilled labor. This means that the human capital constraints that have historically limited export upgrading in developing countries (Hausmann, Hwang, and Rodrik, 2007) are largely absent for FLOP exporting. Moreover, investing in FLOP production capacity today creates an option value: as domestic demand for AI services grows, a country that has built data center infrastructure for export can redirect capacity to serve its own market, seeding a local AI ecosystem without starting from scratch.
[11|Normal|] The opportunity is particularly relevant for the Europe and Central Asia (ECA) region. Several ECA countries — including Turkmenistan, Kyrgyzstan, and the countries of the South Caucasus — have among the world’s lowest electricity prices but limited integration into the global digital economy. Building data centers in these locations and selling compute services to high-cost markets could generate export revenue, attract foreign investment, and accelerate digital infrastructure development.
[12|Normal|] This is not a hypothetical scenario. Major investments in data center infrastructure in developing countries are already underway. In Armenia, a $4 billion AI megaproject backed by NVIDIA and the U.S. government will deploy 50,000 GPUs in a 100 MW facility, positioning the country as home to one of the world’s largest AI computing clusters (Firebird, 2026). Microsoft and G42 are building a $1 billion geothermal-powered data center in Kenya. Saudi Arabia and the UAE have announced multi-gigawatt sovereign AI platforms. Morocco is pursuing a 500 MW data center strategy leveraging renewable energy and proximity to Europe. Malaysia and Indonesia have attracted over $2 billion from Microsoft alone for hyperscale facilities. These investments confirm that FLOP exporting from developing countries is moving from possibility to reality.
[13|Normal|I] However, not all compute services can be exported equally. We distinguish two segments: training and inference. Training — the process of fitting model parameters to data — is a batch workload that can be shipped to the cheapest producer regardless of geographic distance. Inference — the real-time generation of predictions and responses — requires low-latency connections between server and user, so delivery cost increases with distance. This distinction generates a rich set of trade patterns: a country may import training from a distant low-cost producer while sourcing inference domestically or from a nearby hub.
[14|Normal|] The economic stakes are substantial. Consider a hypothetical 40 MW data center in Kyrgyzstan, a country with some of the world’s lowest electricity prices at $0.038/kWh. Such a facility would house approximately 53,000 GPUs and, at current cloud market rates of $2.00–2.50 per GPU-hour, generate $830 million to $1 billion per year in gross revenue, with annual profit of $380–590 million after production costs of $453 million. For context, Kyrgyzstan’s total goods exports were $3.8 billion in 2024 (World Bank); a single large data center could add 10–16% to the country’s export base.
[15|Normal|] To the best of our knowledge, this is the first paper to develop and analyze a formal market for FLOPs as tradeable commodities within an international trade framework. We make three contributions. First, we develop a trade model of FLOP production and export that decomposes the cost of a FLOP into electricity, hardware, and construction components, and introduces an iceberg trade cost for inference that captures latency degradation, alongside a sovereignty premium for domestic production preference. Second, we calibrate the model for 81 countries using data on electricity prices, climate, data center construction costs, and inter-country network latency. Third, we characterize the resulting trade regimes — which countries export, which import, and which adopt hybrid strategies — and show how the sovereignty premium determines the boundary between domestic and foreign sourcing.
[16|Normal|] The remainder of the paper is organized as follows. Section 2 reviews the related literature. Section 3 develops the model, defining the production technology for FLOPs and the trade cost structure that distinguishes training from inference. Section 4 derives the comparative advantage results, presents the buyer’s optimal sourcing problem, and develops a country taxonomy. Section 5 analyzes the make-or-buy decision under country-specific fixed entry costs and the sovereignty premium. Section 6 describes the data. Section 7 calibrates the model and discusses the results. Section 8 concludes.
[17|Heading 1|] 2. Related Literature
[18|Normal|I] Goldfarb and Trefler (2018) argue that AI shifts comparative advantage toward countries with data, human capital, and institutional capacity. Our model introduces a complementary channel: comparative advantage in compute production depends on electricity costs and climate, so resource-rich countries could become compute exporters without domestic AI research industries. Korinek and Stiglitz (2021) raise the possibility that developing countries could be left behind in the AI revolution; FLOP exporting offers a concrete pathway by which energy-rich developing countries could participate. UNCTAD (2025) documents the growing importance of digital services exports from developing economies, and our model provides a structural framework for understanding when and where such exports are viable.
[19|Normal|] A growing literature examines the determinants of data center location. Flucker, Tozer, and Whitehead (2013) show that climate significantly affects data center cooling costs. Oltmanns, Krcmarik, and Gatti (2021) model data center siting as a function of electricity prices, climate, connectivity, and political stability. Liu et al. (2023) study data center placement under renewable energy constraints. These studies focus on where firms should build data centers; our contribution is to embed this location decision in a trade framework that endogenizes the sourcing of compute across countries.
[20|Normal|] The scale of AI-driven electricity demand is documented by the IEA (2025), which reports that global data center electricity consumption could more than double between 2024 and 2030. Goldman Sachs (2024) and EPRI (2024) provide similar estimates for the United States and Europe. This rapid demand growth creates both infrastructure challenges in high-cost locations and export opportunities in low-cost ones — a dynamic that our model formalizes.
[21|Normal|] Our model builds on the trade-in-tasks framework of Grossman and Rossi-Hansberg (2008), where tasks differ in their offshoring costs. Training and inference use the same input (FLOPs) but differ in latency sensitivity, generating task-specific sourcing patterns. The iceberg trade cost for inference connects to Hummels and Schaur (2013), who estimate that each day of shipping time is equivalent to a tariff; in our setting, milliseconds replace days and network latency replaces shipping time. The make-or-buy decision follows the proximity-concentration tradeoff of Brainard (1997) and the heterogeneous-firm trade model of Helpman, Melitz, and Yeaple (2004), where firms sort into exporting versus FDI based on productivity; in our setting, countries sort into importing versus domestic production based on their cost advantage. Melitz (2003) shows that trade liberalization reallocates activity toward more productive firms; analogously, reducing barriers to FLOP trade concentrates production in the most cost-efficient locations.
[22|Normal|] The concept of FLOP exporting as value chain upgrading connects to Hausmann, Hwang, and Rodrik (2007), who show that what a country exports matters for growth. Moving from raw energy exports to compute services represents a shift from primary commodities to higher value-added digital services. Limão and Venables (2001) show that infrastructure quality determines trade costs; in our model, network infrastructure (fiber-optic connectivity) plays the analogous role for digital trade.
[23|Heading 1|] 3. Model Setup
[24|Normal|] A floating-point operation (FLOP) is a single arithmetic computation performed by a processor. Computing power is measured in petaFLOP/s (10¹⁵ FLOPs per second): a current-generation NVIDIA H100 GPU delivers approximately 1 petaFLOP/s at 16-bit precision. Modern AI systems require enormous quantities of compute. Training GPT-3 consumed approximately 300 million petaFLOPs; training GPT-4 required roughly 10 billion petaFLOPs — a 30-fold increase in three years (Epoch AI, 2024). The production of compute at this scale takes place in data centers — purpose-built facilities that house thousands of GPU-equipped servers.
[25|Normal|I] The production process has three main cost components. First, hardware: the GPUs that perform the actual computations. A current-generation NVIDIA H100 costs approximately $25,000 and has a useful life of about three years, during which it operates near-continuously at 90% utilization. The hardware cost is measured in dollars per hour because the GPU purchase price is amortized over its operational lifetime: $25,000 / (3 years × 8,766 hours/year × 90% utilization) ≈ $1.06/hr. This hourly rate makes hardware costs directly comparable and additive with hourly electricity costs. Second, electricity: each GPU draws approximately 700 watts of power, and a large data center may consume 40–100 MW. Electricity is the primary recurring cost and the main source of cross-country variation. Third, construction: the physical facility including the building, power distribution, network connectivity, and cooling systems. Cooling is particularly important because GPUs generate substantial waste heat. In cooler climates, outside air provides free cooling; in hotter climates, mechanical cooling increases total energy consumption. This is captured by the power usage effectiveness (PUE) — the ratio of total facility energy to computing energy — which varies from approximately 1.08 in cold climates to over 1.4 in hot ones (Flucker, Tozer, and Whitehead, 2013).
[26|Normal|] These three components — hardware, electricity, and construction — together determine the unit cost of producing one GPU-hour of compute in a given country. All cost components are expressed in dollars per GPU-hour ($/hr), representing the total hourly operating cost of one GPU including amortized capital. Because GPU prices are set on global markets and do not vary significantly across countries, while electricity prices and construction costs differ substantially, the cross-country variation in FLOP costs is driven primarily by energy and infrastructure. This is the basis of our model.
[27|Heading 2|I] 3.1 Production Technology
[28|Normal|] Consider  countries, each capable of producing compute services (FLOPs). The unit cost of producing one GPU-hour of compute in country  depends on three inputs: electricity, hardware, and data center construction.
[29|Normal|I] The key cost driver is energy intensity — the electrical power a GPU draws during operation. We denote energy intensity by , measured in kilowatts (kW). For the NVIDIA H100,  (700 watts). The actual electricity consumed depends also on the power usage effectiveness PUE(), which captures cooling overhead. We model PUE as:
[30|Normal|] where  is the baseline PUE in cold climates,  is the PUE sensitivity per °C above the reference, and  is the reference temperature.
[31|Normal|] Hardware costs are captured by , the amortized cost of one GPU-hour: , where  is the purchase price,  the lifetime in years,  = 8,766 hours per year, and  the utilization rate. Construction costs enter through , the cost of building one kilowatt of data center IT capacity in country  ($/kW), amortized over the facility lifetime .
[32|Normal|] The total cost per GPU-hour in country  is:
[33|Normal|] The first term is the electricity cost: the PUE-adjusted power draw times the electricity price  ($/kWh). The second term is amortized hardware. The third is amortized construction. Since GPU prices are set on global markets,  is identical across countries. Cross-country variation in  is driven by electricity prices, climate (through PUE), and construction costs.
[34|Heading 2|I] 3.2 Trade Costs
[35|Normal|I] Countries produce and trade two types of compute services. Training services encompass batch workloads: model training, fine-tuning, and large-scale data processing. The client ships its data to where FLOPs are cheapest; the computation executes locally and the output is returned. Since neither input nor output is time-sensitive, network latency plays no role. Inference services encompass real-time workloads: chatbot responses, autonomous decisions, interactive agents. Each query must travel to the server and back within milliseconds, so the service degrades with delivery delay.
[36|Normal|I] Latency, denoted , is the round-trip time for a data packet to travel from server country  to demand center  and back, measured in milliseconds (ms). Within a country, latency is typically 5–10 ms; across continents it can exceed 150 ms. For training, the workload ships to the producer, so effective latency is zero.
[37|Normal|I] Governments and firms may prefer to process data domestically for reasons of national security, regulatory compliance, or political preference. We capture this through a sovereignty premium , which acts as an ad valorem markup on the cost of foreign-sourced compute. When a country sources compute from a foreign producer, the effective cost is inflated by the factor . The sovereignty premium is zero for domestic production.
[38|Normal|] The delivered cost of service  from producer  to demand center  is:
[39|Normal|] where  if  (foreign sourcing) and  if  (domestic);  (training has zero effective latency) and  (inference degrades with latency). The parameter  measures the rate of quality degradation per millisecond of round-trip latency.
[40|Normal|] For training, equation (3) simplifies to : the delivered cost depends only on the production cost and whether the source is foreign. For inference: : the delivered cost depends on production cost, latency, and sovereignty. In this simple model, training concentrates at the globally cheapest FLOP source regardless of distance, while inference disperses toward demand centers bounded by latency.
[41|Heading 1|] 4. Comparative Advantage Results
[42|Normal|I] We now characterize the optimal sourcing decision for a country that consumes compute services. The analysis is structured around two types of countries: importers (countries that purchase FLOPs from abroad) and exporters (countries that produce FLOPs for foreign consumption).
[43|Normal|B] Proposition 1 (Optimal Sourcing). For each service type , demand country  chooses the source  that minimizes the delivered cost:
[44|Normal|I] Training. Since , the buyer’s problem reduces to  = . Country  sources training domestically if and only if . Without the sovereignty premium, all countries import training from the single cheapest global producer. With a positive , countries whose domestic cost falls within the sovereignty band produce domestically.
[45|Normal|I] Inference. Since , the buyer weighs both cost and latency: . A country with low production cost  but high latency to demand center  may be uncompetitive for inference even if it dominates in training. This creates regional inference hubs: countries that combine moderate costs with geographic proximity to major markets.
[46|Normal|B] Country Taxonomy. The model generates a natural classification of countries based on their cost position and geographic proximity to demand centers:
[47|Normal|] Equation (3) generates four possible sourcing regimes for each buyer , depending on whether training and inference are sourced domestically or imported:
[48|Normal|I] (i) Full import . Countries with high  that import both training and inference from abroad. These countries have no cost advantage and rely entirely on foreign compute. Examples: Ireland, Croatia, Greenland.
[49|Normal|I] (ii) Import training, domestic inference . The most common pure-cost regime: the country cannot compete on global training costs but its domestic latency advantage makes local inference cheaper than importing. Examples: Norway, Canada, Brazil, Australia.
[50|Normal|I] (iii) Full domestic . Under pure cost minimization, only the globally cheapest producer (Iran) falls in this category. With a sovereignty premium , this becomes the dominant regime: countries with high production costs still produce domestically because the sovereignty markup makes imports more expensive. For instance, with , countries like Japan ($1.25/hr) and Germany ($1.24/hr) produce both services domestically, even though their costs far exceed those of the cheapest producers.
[51|Normal|I] (iv) Domestic training, import inference . Theoretically possible if a country is the cheapest globally (optimal for zero-latency training) but sufficiently remote that a nearby country offers cheaper inference. Empirically, this regime is empty: the cheapest producer’s cost advantage extends to domestic inference as well.
[52|Normal|I] From the supply side, two specialization patterns emerge. Training exporters are countries with the globally lowest costs, which serve training demand worldwide since training has zero effective latency cost. Regional inference hubs are countries with moderate costs but low latency to major demand centers, which export inference to nearby high-cost countries. Their competitive radius is bounded by latency. Examples: Kosovo (Southeastern Europe), Finland (Baltics), Algeria (Mediterranean).
[53|Normal|] Note that the production cost per GPU-hour is the same regardless of whether the GPU is used for training or inference — both services use the same hardware. The cost difference arises entirely from the trade cost: inference delivered over distance costs more because of the latency markup. From the buyer’s perspective, an inference FLOP costs more than a training FLOP because some compute is effectively lost to latency.
[54|Heading 1|] 5. The Make-or-Buy Decision
[55|Normal|] A country that wishes to produce FLOPs domestically must first build a data center, incurring a country-specific fixed cost . This cost depends on local construction prices, land costs, and regulatory requirements, and is proportional to the construction cost parameter . The entry decision trades off the fixed cost against the expected operating margin.
[56|Normal|B] Proposition 2 (Entry Decision). Country  enters the FLOP export market (builds a data center) if and only if:
[57|Normal|] where  is the volume of compute demanded by country , and the summation ranges over all demand centers  for which  is the optimal source per equation (4). The key insight is that expected volume is determined by the global market, not by country ’s own size. A small country like Kyrgyzstan could, if it is the cheapest producer, attract training demand from the entire world. However, small cheap-energy countries may have  below the global average yet still fail the entry condition if an even cheaper country exists — because the cheapest producer captures all training volume. For inference, the competitive catchment area is limited by latency: a remote country, no matter how cheap, serves only a small geographic radius.
[58|Normal|] Making  country-specific () is important because construction costs vary substantially across countries. A data center in Norway costs more to build than one in Uzbekistan, even if Norway has cheaper electricity. The entry condition thus depends on both the operating margin (driven by ) and the fixed cost (driven by ). As in the heterogeneous-firm trade model of Helpman, Melitz, and Yeaple (2004), only sufficiently productive units — here, countries with sufficiently low cost — find it worthwhile to enter.
[59|Normal|] The sovereignty premium  interacts with the entry decision in two ways. First, it shifts some import demand toward domestic production, reducing the volume available to foreign exporters. Second, it raises the effective price that domestic producers can charge, improving the margin for domestic entry. The combined effect is that the sovereignty premium expands the set of countries that find it profitable to build data centers.
[60|Normal|] The model in Sections 3–5 yields predictions about which countries produce FLOPs and which import them, conditional on observable parameters: electricity prices, temperatures, construction costs, and bilateral latencies. We now calibrate the model using data for 82 countries. Section 6 describes the data sources, and Section 7 presents the calibration results and discusses the implied sourcing patterns for major demand centers.
[61|Heading 1|] 6. Data
[62|Normal|] Calibrating the model requires data on each component of the unit cost in equation (2), as well as bilateral latencies for the trade cost in equation (3). All cost components are measured at 2024–2025 prices.
[63|Normal|I] Electricity prices. For European countries, we use Eurostat industrial electricity prices in the 20,000–69,999 MWh consumption band (nrg_pc_205), which corresponds to large industrial consumers (Eurostat, 2025). For non-European countries, we use national regulator tariff sheets and secondary sources: U.S. Energy Information Administration (EIA, 2025) for the United States; KEPCO for South Korea; national utility tariffs for Central Asian countries (Barki Tojik, AERA, Ministry of Energy of Uzbekistan); and GlobalPetrolPrices (2025) for remaining countries. All prices are converted to USD/kWh at 2024 average exchange rates.
[64|Normal|I] Temperature. Peak summer temperature for each country is computed from ERA5 reanalysis data (Hersbach et al., 2020) as the average monthly maximum in the three warmest months, aggregated across populated grid cells. This enters the PUE model in equation (1) and, through it, equation (2).
[65|Normal|I] Construction costs. Data center construction costs per watt of IT capacity are from the Turner & Townsend Data Centre Construction Cost Index 2025, which reports actual costs ($/W) for 18 countries (Turner & Townsend, 2025). For the remaining countries, we predict construction costs using a cross-sectional regression on GDP per capita (PPP) with . Costs are amortized over 15 years. In equation (2), construction costs are expressed per kilowatt ($/kW); the raw data in $/W is converted by multiplying by 1,000.
[66|Normal|I] Latency. Inter-country round-trip latency is measured using WonderNetwork’s global ping dataset (WonderNetwork, 2024), which records 2.8 million pings across 87 origin cities in 99 countries. For each country pair, we use the median round-trip time (RTT) in milliseconds. Domestic latency defaults to 5 ms where no intra-country measurement is available.
[67|Normal|I] Hardware. We use the NVIDIA H100 SXM GPU as the reference hardware platform: list price $25,000, thermal design power 700W, economic lifetime 3 years, utilization rate 90% (NVIDIA, 2024). This yields an amortized hardware cost /hr. GPU prices are assumed uniform across countries; in practice, export controls raise effective prices for some countries (see Section 7).
[68|Normal|I] Other parameters. The latency degradation parameter is set at , implying that 100 ms of latency inflates inference cost by 8%. The sovereignty premium is . Sensitivity to both parameters is explored in Section 7.
[69|Heading 1|] 7. Calibration and Discussion
[70|Normal|] We calibrate the model for  countries (30 in ECA, 52 non-ECA comparators). The unit cost  represents the total hourly cost of operating one GPU in country , measured in dollars per GPU-hour ($/hr). It is the sum of hourly electricity cost, amortized hardware cost ($1.06/hr), and amortized construction cost. Table 1 reports the results, sorted by total cost.
[71|Normal|I] The regime column reports the optimal sourcing strategy for each country as a demand center, derived from Proposition 1 (equation 4) under pure cost minimization (without the sovereignty premium). Import means the country imports both training and inference. Hybrid means the country imports training from the cheapest global source but produces inference domestically or from a nearby hub. Domestic means the country produces both services domestically because it has the lowest cost including latency.
[72|Normal|] Table A1 in the Appendix reports the full results for all  countries, sorted by total unit cost.
[73|Normal|] The cheapest FLOP producer globally is Iran ($1.10/hr), benefiting from heavily subsidized electricity at $0.005/kWh. Among ECA countries, the five cheapest are Turkmenistan ($1.11/hr, subsidized electricity), Kyrgyzstan ($1.13/hr, hydropower), Russia ($1.14/hr), Kosovo ($1.14/hr), and Ukraine ($1.15/hr). The Nordics benefit from low PUE (1.08–1.10). At the expensive end, Ireland ($1.28/hr) and Greenland ($1.32/hr) face high electricity prices. Construction costs account for 3–6% of total costs, ranging from $0.033/hr (China) to $0.078/hr (Japan, Singapore).
[74|Normal|I] Under pure cost minimization (without sovereignty), 44 of 82 countries (54%) are in full import, 36 (44%) in hybrid, and 1 (1%) in domestic. Training concentrates entirely at the cheapest global producer. Inference organizes into regional hubs: Kosovo serves Southeastern Europe, Algeria the Mediterranean, Finland the Baltics, Canada North America.
[75|Normal|I] A sovereignty premium  shifts 54 countries (66%) to domestic, 26 (32%) to hybrid, and only 1 (1%) remain full import. The sovereignty premium is particularly powerful for inference: since the latency markup within Europe is moderate (10–40 ms, adding 1–3%), even a small domestic preference tips the decision away from importing.
[76|Normal|I] Major demand centers. The model’s predictions vary across major AI demand centers because each faces a different latency geography. For the United States, the pure-cost optimum sources training from Iran and inference from CAN ($1.19/hr) — reflecting Canada’s combination of low cost and minimal cross-border latency. For major European demand centers, inference is sourced from DZA: Germany at $1.18/hr, the United Kingdom at $1.18/hr, and France at $1.17/hr — Algeria’s subsidized electricity and moderate Mediterranean latency make it the European inference hub. For China, the cheapest inference source is KGZ ($1.16/hr), a bordering country with hydropower-based electricity. Russia produces inference domestically even under pure cost minimization ($1.18/hr), as its low energy costs offset moderate latency. The Gulf states present another pattern: Saudi Arabia ($1.17/hr) and the UAE ($1.17/hr) also produce inference domestically, benefiting from subsidized energy and expanding datacenter capacity. These patterns illustrate the model’s core prediction: inference organizes around latency-bounded regional hubs, and each major market has a distinct optimal supplier determined by geography. With a sovereignty premium of 10%, the United States, China, Russia, and the Gulf states all shift to full domestic production, while Germany still imports training but produces inference domestically.
[77|Normal|] Caveats: GPU export controls raise effective  for Iran, Russia, and Belarus beyond what globally uniform hardware costs capture. Grid reliability varies widely across the sample. The EU’s GDPR and AI Act create hard barriers for inference on personal data. Agglomeration economies (Krugman, 1991) favor established hubs despite higher costs.
[78|Normal|I] Governance and political economy. The model treats production costs as the primary determinant of comparative advantage, but the viability of a country as a compute exporter depends critically on institutional factors that are not captured by  alone. Several governance dimensions are essential.
[79|Normal|I] Political stability and property rights. Data center investments are large, long-lived, and immobile. A facility costing hundreds of millions of dollars cannot be relocated if the political environment deteriorates. Investors require credible commitments that contracts will be honored, electricity tariffs will not be retroactively changed, and assets will not be expropriated. Several of the cheapest producers in our calibration — Iran, Turkmenistan, Uzbekistan — rank poorly on property rights and rule of law indices. This suggests that the effective cost of producing FLOPs in these countries is higher than the engineering cost alone, because investors demand a risk premium. Formally, the fixed entry cost  should be interpreted as including not only construction costs but also the institutional premium required to attract foreign capital.
[80|Normal|I] Regulatory environment and data governance. Countries that host compute for foreign clients must offer credible data protection frameworks. The European Union’s GDPR restricts the transfer of personal data to countries without “adequacy” determinations, effectively barring inference on EU citizen data in most developing countries. The EU AI Act imposes additional compliance requirements. These regulations act as non-tariff barriers that segment the global compute market along regulatory lines, reinforcing the sovereignty premium  as a structural feature of the market rather than a mere preference parameter.
[81|Normal|I] Grid reliability and infrastructure. Data centers require uninterrupted power. Countries with frequent outages face additional costs for backup generation and battery storage that are not reflected in the headline electricity price. Grid reliability varies dramatically across the sample: Nordic countries experience near-zero unplanned outages, while some Central Asian and African countries face intermittent supply. The effective electricity cost should therefore be understood as a reliability-adjusted price.
[82|Normal|I] Geopolitical risk and export controls. The United States imposes export controls on advanced GPUs (NVIDIA H100 and above) to China, Russia, Iran, and other countries deemed strategic competitors. These controls raise the effective hardware cost  for affected countries, potentially to the point where the cost advantage from cheap electricity is entirely offset. The controls also create uncertainty about future access to next-generation hardware, which discourages long-term investment. For countries not subject to controls, proximity to a geopolitically stable supplier becomes an additional locational advantage.
[83|Normal|I] Corruption and rent-seeking. Large infrastructure investments in weak-governance environments are vulnerable to corruption, permitting delays, and rent extraction by local elites. The subsidized electricity prices that make some countries appear cheap may themselves be politically fragile: energy subsidies are frequently targeted for fiscal consolidation, and a subsidy reversal can eliminate a country’s cost advantage overnight. The sustainability of the cost structure is thus as important as its current level.
[84|Normal|] Taken together, these governance factors suggest that the set of viable compute exporters is considerably smaller than the set of low-cost producers identified by the model. The countries best positioned to develop FLOP export industries are those that combine low energy costs with adequate institutional quality — a set that includes the Nordic countries, Canada, and parts of the Gulf and Central Asia where governance investments are actively underway.
[85|Normal|I] Model extensions. The framework developed in this paper admits several natural extensions that we leave for future work.
[86|Normal|I] First, the static entry decision could be extended to allow for dynamic entry with capacity constraints: building a 100 MW data center takes 18–24 months, and demand may shift during construction. Second, heterogeneous demand would allow segmentation by latency tolerance — financial trading requires microsecond latency while batch analytics tolerates seconds — generating vertical specialization across quality tiers.
[87|Normal|I] Third, endogenous electricity prices with upward-sloping supply curves would capture the feedback from data center entry to energy costs, as illustrated by Ireland’s moratorium on new connections. Fourth, carbon pricing and renewable energy certificates could introduce a “green premium” favoring countries with hydropower or geothermal energy, while penalizing coal-dependent grids.
[88|Normal|I] Fifth, strategic interaction — oligopolistic pricing, capacity pre-emption, or government–hyperscaler bargaining — would better capture the concentrated market structure of the industry. Finally, governance as a cost shifter could be modeled as a multiplicative premium on , reducing the predicted set of exporters and sharpening the policy implications for institutional reform.
[89|Heading 1|] 8. Conclusion
[90|Normal|] This paper developed a trade model for computing services (FLOPs) in which countries produce and export computation based on their electricity prices, climate, and construction costs. We distinguished two service types — latency-insensitive training and latency-sensitive inference — and introduced a sovereignty premium to capture governments’ preference for domestic data processing. We derived buyers’ optimal sourcing decisions (Proposition 1) and producers’ entry conditions (Proposition 2), then calibrated the model for 82 countries using data on electricity prices, temperatures, construction costs, and bilateral latencies.
[91|Normal|] Training and inference both consume FLOPs, but training ships the workload to cheap FLOPs while inference demands that FLOPs be close to the user. This factor-intensity asymmetry generates geographic separation of training and inference, amplified by the sovereignty premium. Across 82 countries, cheap-energy peripheries serve as FLOP exporters for training, while inference organizes into regional hubs bounded by latency. The sovereignty premium rationalizes widespread domestic investment, shifting the majority of countries from import to domestic production. The model generates a country taxonomy — full importers, training exporters, inference hubs, and hybrid regimes — that maps onto observed investment patterns.
[92|Normal|] For developing countries, the results point to a new avenue for economic participation in the global economy. Exporting compute services allows countries with cheap energy but limited industrial capacity to convert a natural resource — electricity — into a high-value digital export, bypassing the traditional path of building a manufacturing base. Countries like Kyrgyzstan, Uzbekistan, and Egypt, which rank among the cheapest FLOP producers in our calibration, could capture a share of the rapidly growing global AI compute market. This represents a form of value chain upgrading that does not require a domestic AI research ecosystem: the country need not develop frontier models, only provide the infrastructure on which others train and deploy them. In this sense, FLOP exporting is the digital equivalent of resource-based industrialization — but with the advantage that the “resource” (electricity) is renewable and the product (compute) serves the fastest-growing sector of the world economy.
[93|Normal|] The policy implications are asymmetric. Restricting training imports raises costs without proximity benefit, since training is latency-insensitive. Supporting domestic inference has a genuine latency rationale but is less justified for countries close to low-cost neighbors. For developing countries seeking to enter the compute export market, the binding constraints are not technological but institutional: reliable power grids, political stability, data governance frameworks, and international connectivity determine whether cost advantages on paper translate into viable export industries.
[94|Normal|] 
[95|Heading 1|] Appendix
[96|Normal|B] Table A1. Unit cost of FLOP production by country (H100 GPU-hour)
[97|Normal|] 
[98|Heading 1|] References
[99|Normal|I] Antràs, P., and E. Helpman. (2004). “Global Sourcing.” Journal of Political Economy, 112(3): 552–580.
[100|Normal|I] Brainard, S. L. (1997). “An Empirical Assessment of the Proximity-Concentration Tradeoff.” American Economic Review, 87(4): 520–544.
[101|Normal|I] Deloitte. (2025). “Technology, Media, and Telecommunications Predictions 2026.” Deloitte Insights.
[102|Normal|] EIA. (2025). Electric Power Monthly. U.S. Energy Information Administration.
[103|Normal|] Epoch AI. (2024). “The Training Compute of Notable AI Models.” epochai.org.
[104|Normal|] EPRI. (2024). “Powering Intelligence: Analyzing AI and Data Center Energy Consumption.” Electric Power Research Institute.
[105|Normal|I] Eurostat. (2025). Electricity Prices for Non-Household Consumers (nrg_pc_205). Luxembourg: Eurostat.
[106|Normal|] Firebird. (2026). “Phase 2 of Armenia AI Megaproject, Scaling to $4 Billion and 50,000 GPUs.” Press release, January 2026.
[107|Normal|I] Flucker, S., R. Tozer, and R. Whitehead. (2013). “Data Centre Energy Efficiency Analysis.” Building Services Engineering Research and Technology, 34(1): 103–117.
[108|Normal|I] GlobalPetrolPrices. (2025). Electricity Prices Around the World. globalpetrolprices.com.
[109|Normal|I] Goldfarb, A., and D. Trefler. (2018). “AI and International Trade.” In The Economics of Artificial Intelligence. Chicago: Univ. of Chicago Press, pp. 463–492.
[110|Normal|I] Goldman Sachs. (2024). “AI Is Poised to Drive 165% Increase in Data Center Power Demand.” Goldman Sachs Research.
[111|Normal|I] Grossman, G. M., and E. Rossi-Hansberg. (2008). “Trading Tasks: A Simple Theory of Offshoring.” American Economic Review, 98(5): 1978–1997.
[112|Normal|I] Hausmann, R., J. Hwang, and D. Rodrik. (2007). “What You Export Matters.” Journal of Economic Growth, 12(1): 1–25.
[113|Normal|I] Helpman, E., Melitz, M. J., and S. R. Yeaple. (2004). “Export Versus FDI with Heterogeneous Firms.” American Economic Review, 94(1): 300–316.
[114|Normal|I] Hersbach, H., et al. (2020). “The ERA5 Global Reanalysis.” Quarterly Journal of the Royal Meteorological Society, 146(730): 1999–2049.
[115|Normal|I] Hummels, D., and G. Schaur. (2013). “Time as a Trade Barrier.” American Economic Review, 103(7): 2935–2959.
[116|Normal|] IEA. (2025). “Energy Demand from AI.” Published online at iea.org.
[117|Normal|I] Korinek, A., and J. Stiglitz. (2021). “AI, Globalization, and Strategies for Economic Development.” NBER Working Paper No. 28453.
[118|Normal|I] Krugman, P. (1991). “Increasing Returns and Economic Geography.” Journal of Political Economy, 99(3): 483–499.
[119|Normal|I] Limão, N., and A. J. Venables. (2001). “Infrastructure, Geographical Disadvantage, Transport Costs, and Trade.” World Bank Economic Review, 15(3): 451–479.
[120|Normal|I] Liu, Z., A. Wierman, Y. Chen, B. Raber, and J. Moriarty. (2023). “Sustainability of Data Center Digital Twins.” Proceedings of ACM e-Energy, pp. 178–189.
[121|Normal|] MarketsandMarkets. (2025). “GPU Server Market — Global Forecast to 2030.”
[122|Normal|I] Melitz, M. J. (2003). “The Impact of Trade on Intra-Industry Reallocations and Aggregate Industry Productivity.” Econometrica, 71(6): 1695–1725.
[123|Normal|] NVIDIA. (2024). NVIDIA H100 Tensor Core GPU Datasheet. nvidia.com.
[124|Normal|I] Oltmanns, J., D. Krcmarik, and R. Gatti. (2021). “Data Centre Site Selection.” Journal of Property Investment & Finance, 39(1): 55–72.
[125|Normal|] Samuelson, P. (1954). “The Transfer Problem and Transport Costs, II.” Economic Journal, 64(254): 264–289.
[126|Normal|I] Turner & Townsend. (2025). Data Centre Construction Cost Index 2025. turnerandtownsend.com.
[127|Normal|] UNCTAD. (2025). Technology and Innovation Report 2025. Geneva: United Nations.
[128|Normal|] Uptime Institute. (2024). “Data Center Staffing: Trends and Best Practices.”
[129|Normal|I] WonderNetwork. (2024). Global Ping Statistics. wondernetwork.com.
[130|Normal|I] World Bank. (2024). World Development Indicators. Washington, DC.